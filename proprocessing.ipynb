{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob \n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataReader(path_names):\n",
    "    data_n = pd.DataFrame()\n",
    "    for i in path_names:\n",
    "        load_data = pd.read_csv(i,header=None)\n",
    "        data_n = pd.concat([data_n,load_data],ignore_index=True)\n",
    "    return data_n\n",
    "\n",
    "\n",
    "def downSampler(data,a,b):\n",
    "    data_decreased = pd.DataFrame()\n",
    "    x = b\n",
    "    for i in range(int(len(data)/x)):\n",
    "        data_decreased = data_decreased.append(data.iloc[a:b,:].sum()/x,ignore_index=True)\n",
    "        a += x\n",
    "        b += x\n",
    "    return data_decreased\n",
    "\n",
    "\n",
    "def FFT(data):\n",
    "    autocorr = signal.fftconvolve(data,data[::-1],mode='full')\n",
    "    return pd.DataFrame(autocorr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_file_names = glob.glob(\"C:/Users/bhanu/Documents/Projects/Major/Data/normal/*.csv\")\n",
    "data_n = dataReader(normal_file_names)\n",
    "data_n = downSampler(data_n, 0, 5000)\n",
    "data_n = FFT(data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3             4         5         6   \\\n",
      "0  0.000030 -0.000230  0.000798 -0.001137  5.032000e-07  0.001035 -0.000850   \n",
      "1 -0.000222  0.000285  0.000972 -0.000015 -2.265208e-03  0.000113  0.001313   \n",
      "2 -0.000274 -0.001071  0.002893  0.002269 -2.746748e-04  0.000799  0.002136   \n",
      "3  0.001115 -0.001017  0.003275 -0.000789  5.808922e-03  0.003562 -0.001351   \n",
      "4 -0.000274 -0.001071  0.002893  0.002269 -2.746748e-04  0.000799  0.002136   \n",
      "5 -0.000222  0.000285  0.000972 -0.000015 -2.265208e-03  0.000113  0.001313   \n",
      "6  0.000030 -0.000230  0.000798 -0.001137  5.032000e-07  0.001035 -0.000850   \n",
      "\n",
      "         7         8         9         10        11        12        13  \\\n",
      "0  0.000544 -0.000537 -0.000741  0.000049  0.000422  0.000293  0.000245   \n",
      "1 -0.000825  0.004777 -0.000962 -0.000845  0.000880 -0.001088 -0.000487   \n",
      "2 -0.002357  0.004324  0.000968 -0.000389  0.000639  0.000239 -0.001538   \n",
      "3 -0.003872  0.000123  0.002746  0.001168  0.000302  0.003836 -0.001466   \n",
      "4 -0.002357  0.004324  0.000968 -0.000389  0.000639  0.000239 -0.001538   \n",
      "5 -0.000825  0.004777 -0.000962 -0.000845  0.000880 -0.001088 -0.000487   \n",
      "6  0.000544 -0.000537 -0.000741  0.000049  0.000422  0.000293  0.000245   \n",
      "\n",
      "         14  \n",
      "0  0.000010  \n",
      "1  0.000298  \n",
      "2  0.001311  \n",
      "3  0.002055  \n",
      "4  0.001311  \n",
      "5  0.000298  \n",
      "6  0.000010  \n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('C:/Users/bhanu/Documents/Projects/Major/Test_data/test_imb2.csv')\n",
    "test = downSampler(test, 0, 500)\n",
    "test = FFT(test)\n",
    "print(test)\n",
    "test.to_csv('test_imb.csv',header=False,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0    -0.000250  0.000030 -0.000029  0.006429  0.000139  0.014553 -0.040694   \n",
      "1    -0.000612 -0.000108 -0.000096  0.001689  0.003106  0.053009  0.049198   \n",
      "2     0.000618  0.000065 -0.000022  0.001640 -0.001142  0.034010 -0.010943   \n",
      "3     0.001175  0.000303  0.000160 -0.002560 -0.001922 -0.016620 -0.046446   \n",
      "4    -0.001325 -0.000081 -0.000014  0.018337  0.004482  0.025910 -0.051182   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "4894 -0.001325 -0.000081 -0.000014  0.018337  0.004482  0.025910 -0.051182   \n",
      "4895  0.001175  0.000303  0.000160 -0.002560 -0.001922 -0.016620 -0.046446   \n",
      "4896  0.000618  0.000065 -0.000022  0.001640 -0.001142  0.034010 -0.010943   \n",
      "4897 -0.000612 -0.000108 -0.000096  0.001689  0.003106  0.053009  0.049198   \n",
      "4898 -0.000250  0.000030 -0.000029  0.006429  0.000139  0.014553 -0.040694   \n",
      "\n",
      "            7         8         9         10  \n",
      "0    -0.007364 -0.214507 -0.005584 -0.004663  \n",
      "1     0.008777  0.079602 -0.001739 -0.005087  \n",
      "2    -0.003066 -0.010655 -0.004237  0.072586  \n",
      "3    -0.009934 -0.140365 -0.006903  0.049941  \n",
      "4    -0.011151 -0.326563 -0.012461 -0.025808  \n",
      "...        ...       ...       ...       ...  \n",
      "4894 -0.011151 -0.326563 -0.012461 -0.025808  \n",
      "4895 -0.009934 -0.140365 -0.006903  0.049941  \n",
      "4896 -0.003066 -0.010655 -0.004237  0.072586  \n",
      "4897  0.008777  0.079602 -0.001739 -0.005087  \n",
      "4898 -0.007364 -0.214507 -0.005584 -0.004663  \n",
      "\n",
      "[4899 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/bhanu/Documents/Projects/Major/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_file_names_6g = glob.glob(path+'/imbalance/6g/*.csv')\n",
    "imbalance_file_names_10g = glob.glob(path+'/imbalance/10g/*.csv')\n",
    "imbalance_file_names_15g = glob.glob(path+'/imbalance/15g/*.csv')\n",
    "imbalance_file_names_20g = glob.glob(path+'/imbalance/20g/*.csv')\n",
    "imbalance_file_names_25g = glob.glob(path+'/imbalance/25g/*.csv')\n",
    "imbalance_file_names_30g = glob.glob(path+'/imbalance/30g/*.csv')\n",
    "data_6g = dataReader(imbalance_file_names_6g)\n",
    "data_10g = dataReader(imbalance_file_names_10g)\n",
    "data_15g = dataReader(imbalance_file_names_15g)\n",
    "data_20g = dataReader(imbalance_file_names_20g)\n",
    "data_25g = dataReader(imbalance_file_names_25g)\n",
    "data_30g = dataReader(imbalance_file_names_30g)\n",
    "data_6g = downSampler(data_6g, 0, 5000)\n",
    "data_10g = downSampler(data_10g, 0, 5000)\n",
    "data_15g = downSampler(data_15g, 0, 5000)\n",
    "data_20g = downSampler(data_20g, 0, 5000)\n",
    "data_25g = downSampler(data_25g, 0, 5000)\n",
    "data_30g = downSampler(data_30g, 0, 5000)\n",
    "data_6g = FFT(data_6g)\n",
    "data_10g = FFT(data_10g)\n",
    "data_15g = FFT(data_15g)\n",
    "data_20g = FFT(data_20g)\n",
    "data_25g = FFT(data_25g)\n",
    "data_30g = FFT(data_30g)\n",
    "data_imbalance = pd.concat([data_6g,data_10g,data_15g,data_20g,data_25g,data_30g],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13696\n",
      "18796\n",
      "18796\n",
      "51288\n"
     ]
    }
   ],
   "source": [
    "overhang_bf_names_0g = glob.glob(path+'/overhang/ball_fault/0g/*.csv')\n",
    "overhang_bf_names_6g = glob.glob(path+'/overhang/ball_fault/6g/*.csv')\n",
    "overhang_bf_names_20g = glob.glob(path+'/overhang/ball_fault/20g/*.csv')\n",
    "overhang_bf_names_35g = glob.glob(path+'/overhang/ball_fault/35g/*.csv')\n",
    "data_0g = dataReader(overhang_bf_names_0g)\n",
    "data_6g = dataReader(overhang_bf_names_6g)\n",
    "data_20g = dataReader(overhang_bf_names_20g)\n",
    "data_35g = dataReader(overhang_bf_names_35g)\n",
    "data_0g = downSampler(data_0g, 0, 5000)\n",
    "data_6g = downSampler(data_6g, 0, 5000)\n",
    "data_20g = downSampler(data_20g, 0, 5000)\n",
    "data_35g = downSampler(data_35g, 0, 5000)\n",
    "data_0g = FFT(data_0g)\n",
    "data_6g = FFT(data_6g)\n",
    "data_20g = FFT(data_20g)\n",
    "data_35g = FFT(data_35g)\n",
    "\n",
    "data_oh_bf = pd.concat([data_0g,data_6g,data_20g,data_35g],ignore_index=True)\n",
    "\n",
    "print(len(data_oh_bf))\n",
    "\n",
    "overhang_cf_names_0g = glob.glob(path+'/overhang/cage_fault/0g/*.csv')\n",
    "overhang_cf_names_6g = glob.glob(path+'/overhang/cage_fault/6g/*.csv')\n",
    "overhang_cf_names_20g = glob.glob(path+'/overhang/cage_fault/20g/*.csv')\n",
    "overhang_cf_names_35g = glob.glob(path+'/overhang/cage_fault/35g/*.csv')\n",
    "data_0g = dataReader(overhang_cf_names_0g)\n",
    "data_6g = dataReader(overhang_cf_names_6g)\n",
    "data_20g = dataReader(overhang_cf_names_20g)\n",
    "data_35g = dataReader(overhang_cf_names_35g)\n",
    "data_0g = downSampler(data_0g, 0, 5000)\n",
    "data_6g = downSampler(data_6g, 0, 5000)\n",
    "data_20g = downSampler(data_20g, 0, 5000)\n",
    "data_35g = downSampler(data_35g, 0, 5000)\n",
    "data_0g = FFT(data_0g)\n",
    "data_6g = FFT(data_6g)\n",
    "data_20g = FFT(data_20g)\n",
    "data_35g = FFT(data_35g)\n",
    "data_oh_cf = pd.concat([data_0g,data_6g,data_20g,data_35g],ignore_index=True)\n",
    "print(len(data_oh_cf))\n",
    "\n",
    "overhang_or_names_0g = glob.glob(path+'/overhang/outer_race/0g/*.csv')\n",
    "overhang_or_names_6g = glob.glob(path+'/overhang/outer_race/6g/*.csv')\n",
    "overhang_or_names_20g = glob.glob(path+'/overhang/outer_race/20g/*.csv')\n",
    "overhang_or_names_35g = glob.glob(path+'/overhang/outer_race/35g/*.csv')\n",
    "data_0g = dataReader(overhang_or_names_0g)\n",
    "data_6g = dataReader(overhang_or_names_6g)\n",
    "data_20g = dataReader(overhang_or_names_20g)\n",
    "data_35g = dataReader(overhang_or_names_35g)\n",
    "data_0g = downSampler(data_0g, 0, 5000)\n",
    "data_6g = downSampler(data_6g, 0, 5000)\n",
    "data_20g = downSampler(data_20g, 0, 5000)\n",
    "data_35g = downSampler(data_35g, 0, 5000)\n",
    "data_0g = FFT(data_0g)\n",
    "data_6g = FFT(data_6g)\n",
    "data_20g = FFT(data_20g)\n",
    "data_35g = FFT(data_35g)\n",
    "data_oh_or = pd.concat([data_0g,data_6g,data_20g,data_35g],ignore_index=True)\n",
    "print(len(data_oh_or))\n",
    "\n",
    "data_overhang = pd.concat([data_oh_bf,data_oh_cf,data_oh_or],ignore_index=True)\n",
    "print(len(data_overhang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18596\n",
      "18796\n",
      "18396\n",
      "55788\n"
     ]
    }
   ],
   "source": [
    "underhang_bf_names_0g = glob.glob(path+'/underhang/ball_fault/0g/*.csv')\n",
    "underhang_bf_names_6g = glob.glob(path+'/underhang/ball_fault/6g/*.csv')\n",
    "underhang_bf_names_20g = glob.glob(path+'/underhang/ball_fault/20g/*.csv')\n",
    "underhang_bf_names_35g = glob.glob(path+'/underhang/ball_fault/35g/*.csv')\n",
    "data_0g = dataReader(underhang_bf_names_0g)\n",
    "data_6g = dataReader(underhang_bf_names_6g)\n",
    "data_20g = dataReader(underhang_bf_names_20g)\n",
    "data_35g = dataReader(underhang_bf_names_35g)\n",
    "data_0g = downSampler(data_0g, 0, 5000)\n",
    "data_6g = downSampler(data_6g, 0, 5000)\n",
    "data_20g = downSampler(data_20g, 0, 5000)\n",
    "data_35g = downSampler(data_35g, 0, 5000)\n",
    "data_0g = FFT(data_0g)\n",
    "data_6g = FFT(data_6g)\n",
    "data_20g = FFT(data_20g)\n",
    "data_35g = FFT(data_35g)\n",
    "data_uh_bf = pd.concat([data_0g,data_6g,data_20g,data_35g],ignore_index=True)\n",
    "print(len(data_uh_bf))\n",
    "\n",
    "underhang_cf_names_0g = glob.glob(path+'/underhang/cage_fault/0g/*.csv')\n",
    "underhang_cf_names_6g = glob.glob(path+'/underhang/cage_fault/6g/*.csv')\n",
    "underhang_cf_names_20g = glob.glob(path+'/underhang/cage_fault/20g/*.csv')\n",
    "underhang_cf_names_35g = glob.glob(path+'/underhang/cage_fault/35g/*.csv')\n",
    "data_0g = dataReader(underhang_cf_names_0g)\n",
    "data_6g = dataReader(underhang_cf_names_6g)\n",
    "data_20g = dataReader(underhang_cf_names_20g)\n",
    "data_35g = dataReader(underhang_cf_names_35g)\n",
    "data_0g = downSampler(data_0g, 0, 5000)\n",
    "data_6g = downSampler(data_6g, 0, 5000)\n",
    "data_20g = downSampler(data_20g, 0, 5000)\n",
    "data_35g = downSampler(data_35g, 0, 5000)\n",
    "data_0g = FFT(data_0g)\n",
    "data_6g = FFT(data_6g)\n",
    "data_20g = FFT(data_20g)\n",
    "data_35g = FFT(data_35g)\n",
    "data_uh_cf = pd.concat([data_0g,data_6g,data_20g,data_35g],ignore_index=True)\n",
    "print(len(data_uh_cf))\n",
    "\n",
    "underhang_or_names_0g = glob.glob(path+'/underhang/outer_race/0g/*.csv')\n",
    "underhang_or_names_6g = glob.glob(path+'/underhang/outer_race/6g/*.csv')\n",
    "underhang_or_names_20g = glob.glob(path+'/underhang/outer_race/20g/*.csv')\n",
    "underhang_or_names_35g = glob.glob(path+'/underhang/outer_race/35g/*.csv')\n",
    "data_0g = dataReader(underhang_or_names_0g)\n",
    "data_6g = dataReader(underhang_or_names_6g)\n",
    "data_20g = dataReader(underhang_or_names_20g)\n",
    "data_35g = dataReader(underhang_or_names_35g)\n",
    "data_0g = downSampler(data_0g, 0, 5000)\n",
    "data_6g = downSampler(data_6g, 0, 5000)\n",
    "data_20g = downSampler(data_20g, 0, 5000)\n",
    "data_35g = downSampler(data_35g, 0, 5000)\n",
    "data_0g = FFT(data_0g)\n",
    "data_6g = FFT(data_6g)\n",
    "data_20g = FFT(data_20g)\n",
    "data_35g = FFT(data_35g)\n",
    "data_uh_or = pd.concat([data_0g,data_6g,data_20g,data_35g],ignore_index=True)\n",
    "print(len(data_uh_or))\n",
    "\n",
    "data_underhang = pd.concat([data_uh_bf,data_uh_cf,data_uh_or],ignore_index=True)\n",
    "print(len(data_underhang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55788\n"
     ]
    }
   ],
   "source": [
    "print(len(data_underhang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizonatal_ma_05 = glob.glob(path+'/horizontal-misalignment/0.5mm/*.csv')\n",
    "horizonatal_ma_10 = glob.glob(path+'/horizontal-misalignment/1.0mm/*.csv')\n",
    "horizonatal_ma_15 = glob.glob(path+'/horizontal-misalignment/1.5mm/*.csv')\n",
    "horizonatal_ma_20 = glob.glob(path+'/horizontal-misalignment/2.0mm/*.csv')\n",
    "data_05 = dataReader(horizonatal_ma_05)\n",
    "data_10 = dataReader(horizonatal_ma_10)\n",
    "data_15 = dataReader(horizonatal_ma_15)\n",
    "data_20 = dataReader(horizonatal_ma_20)\n",
    "data_05 = downSampler(data_05, 0, 5000)\n",
    "data_10 = downSampler(data_10, 0, 5000)\n",
    "data_15 = downSampler(data_15, 0, 5000)\n",
    "data_20 = downSampler(data_20, 0, 5000)\n",
    "data_05 = FFT(data_05)\n",
    "data_10 = FFT(data_10)\n",
    "data_15 = FFT(data_15)\n",
    "data_20 = FFT(data_20)\n",
    "\n",
    "data_h_ma = pd.concat([data_05,data_10,data_15,data_20],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_ma_051 = glob.glob(path+'/vertical-misalignment/0.51mm/*.csv')\n",
    "vertical_ma_063 = glob.glob(path+'/vertical-misalignment/0.63mm/*.csv')\n",
    "vertical_ma_127 = glob.glob(path+'/vertical-misalignment/1.27mm/*.csv')\n",
    "vertical_ma_140 = glob.glob(path+'/vertical-misalignment/1.40mm/*.csv')\n",
    "vertical_ma_178 = glob.glob(path+'/vertical-misalignment/1.78mm/*.csv')\n",
    "vertical_ma_190 = glob.glob(path+'/vertical-misalignment/1.90mm/*.csv')\n",
    "data_05 = dataReader(vertical_ma_051)\n",
    "data_10 = dataReader(vertical_ma_063)\n",
    "data_15 = dataReader(vertical_ma_127)\n",
    "data_20 = dataReader(vertical_ma_140)\n",
    "data_25 = dataReader(vertical_ma_178)\n",
    "data_30 = dataReader(vertical_ma_190)\n",
    "data_05 = downSampler(data_05, 0, 5000)\n",
    "data_10 = downSampler(data_10, 0, 5000)\n",
    "data_15 = downSampler(data_15, 0, 5000)\n",
    "data_20 = downSampler(data_20, 0, 5000)\n",
    "data_25 = downSampler(data_25, 0, 5000)\n",
    "data_30 = downSampler(data_30, 0, 5000)\n",
    "data_05 = FFT(data_05)\n",
    "data_10 = FFT(data_10)\n",
    "data_15 = FFT(data_15)\n",
    "data_20 = FFT(data_20)\n",
    "data_25 = FFT(data_25)\n",
    "data_30 = FFT(data_30)\n",
    "\n",
    "data_v_ma = pd.concat([data_05,data_10,data_15,data_20,data_25,data_30],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_n,data_imbalance, data_overhang,data_underhang,data_h_ma,data_v_ma],ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190359\n",
      "              0         1         2         3         4         5         6   \\\n",
      "0      -0.000250  0.000030 -0.000029  0.006429  0.000139  0.014553 -0.040694   \n",
      "1      -0.000612 -0.000108 -0.000096  0.001689  0.003106  0.053009  0.049198   \n",
      "2       0.000618  0.000065 -0.000022  0.001640 -0.001142  0.034010 -0.010943   \n",
      "3       0.001175  0.000303  0.000160 -0.002560 -0.001922 -0.016620 -0.046446   \n",
      "4      -0.001325 -0.000081 -0.000014  0.018337  0.004482  0.025910 -0.051182   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "190354 -0.000083 -0.000068 -0.000044  0.007103  0.003401 -0.013768  0.035766   \n",
      "190355  0.000033  0.000159  0.000005  0.007259  0.002291 -0.001789  0.022520   \n",
      "190356 -0.000250 -0.000070 -0.000026 -0.005690 -0.001998 -0.021736 -0.020471   \n",
      "190357 -0.000329 -0.000231 -0.000023 -0.002617 -0.000855 -0.011591 -0.003598   \n",
      "190358 -0.000135  0.000040 -0.000007  0.002844  0.000925  0.010116  0.017297   \n",
      "\n",
      "              7         8         9         10  \n",
      "0      -0.007364 -0.214507 -0.005584 -0.004663  \n",
      "1       0.008777  0.079602 -0.001739 -0.005087  \n",
      "2      -0.003066 -0.010655 -0.004237  0.072586  \n",
      "3      -0.009934 -0.140365 -0.006903  0.049941  \n",
      "4      -0.011151 -0.326563 -0.012461 -0.025808  \n",
      "...          ...       ...       ...       ...  \n",
      "190354  0.006840  0.300710  0.046988  0.133394  \n",
      "190355  0.008123  0.222745  0.032107  1.996918  \n",
      "190356 -0.004297 -0.069666 -0.016475  1.985091  \n",
      "190357 -0.000047  0.157566  0.022436  1.475499  \n",
      "190358  0.006123  0.256923  0.047717  0.983901  \n",
      "\n",
      "[190359 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190359\n"
     ]
    }
   ],
   "source": [
    "y_1 = pd.DataFrame(np.zeros(int(len(data_n)),dtype=int))\n",
    "y_2 = pd.DataFrame(np.ones(int(len(data_imbalance)),dtype=int))\n",
    "y_3 = pd.DataFrame(np.full((int(len(data_overhang)),1),2))\n",
    "y_4 = pd.DataFrame(np.full((int(len(data_underhang)),1),3))\n",
    "y_5 = pd.DataFrame(np.full((int(len(data_h_ma)),1),4))\n",
    "y_6 = pd.DataFrame(np.full((int(len(data_v_ma)),1),5))\n",
    "\n",
    "y = pd.concat([y_1,y_2,y_3,y_4,y_5,y_6], ignore_index=True)\n",
    "print(len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data_n.to_csv('processed_data_normal.csv', header=False, index=False)\n",
    "data_imbalance.to_csv('processed_data_imbalance.csv', header=False, index=False)\n",
    "data_overhang.to_csv('processed_data_oh.csv', header=False, index=False)\n",
    "data_underhang.to_csv('processed_data_uh.csv', header=False, index=False)\n",
    "data_h_ma.to_csv('processed_data_hma.csv', header=False, index=False)\n",
    "data_v_ma.to_csv('processed_data_vma.csv', header=False, index=False)'''\n",
    "\n",
    "data.to_csv('processed_data_input5.csv', header=False, index=False)\n",
    "y.to_csv('processed_data_output5.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0be64cfe9fe393d336b146bd657e84fad30bc0b70a824b15097c5e9f24e3bfaa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('project_py')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
